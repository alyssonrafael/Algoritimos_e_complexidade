# Projeto de AutomaÃ§Ã£o em Python ğŸ¤–

Este projeto Ã© uma suÃ­te de automaÃ§Ã£o desenvolvida em Python, contendo robÃ´s para interagir com redes sociais e coletar dados da web. Atualmente, o projeto inclui dois mÃ³dulos principais:

1. **Bot do Instagram**: Um robÃ´ robusto que realiza login, lida com verificaÃ§Ã£o de duas etapas (2FA) e extrai informaÃ§Ãµes de perfis.
2. **Coletor de NotÃ­cias**: Um scraper que coleta as Ãºltimas manchetes do portal de notÃ­cias G1.

---

## ğŸ“‚ Estrutura do Projeto

O projeto Ã© organizado de forma modular para facilitar a manutenÃ§Ã£o e a adiÃ§Ã£o de novas automaÃ§Ãµes.

```
web_scraping_com_selenium/
â”œâ”€â”€ .env                  # Arquivo para credenciais (deve ser criado localmente)
â”œâ”€â”€ requirements.txt      # Lista de dependÃªncias do projeto
â”œâ”€â”€ main.py               # Orquestrador principal que executa os robÃ´s
â”œâ”€â”€ boot_login/
â”‚   â”œâ”€â”€ __init__.py       # Torna este diretÃ³rio um pacote Python.
â”‚   â”œâ”€â”€ main.py           # LÃ³gica do bot do Instagram
â”‚   â””â”€â”€ README.md         # DocumentaÃ§Ã£o especÃ­fica do bot
â””â”€â”€ noticias/
    â”œâ”€â”€ __init__.py       # Torna este diretÃ³rio um pacote Python.
    â”œâ”€â”€ main.py           # LÃ³gica do coletor de notÃ­cias
    â””â”€â”€ README.md         # DocumentaÃ§Ã£o especÃ­fica do coletor
```

---

## âœ¨ Funcionalidades

- **Interface de Menu**: Orquestrador central para escolher qual robÃ´ executar.
- **Gerenciamento de DependÃªncias**: Arquivo `requirements.txt` para fÃ¡cil instalaÃ§Ã£o.
- **SeguranÃ§a**: Uso de variÃ¡veis de ambiente (`.env`) para proteger credenciais.
- **AutomaÃ§Ã£o do Instagram**:
  - Login automatizado com comportamento "humano".
  - Suporte para intervenÃ§Ã£o manual na verificaÃ§Ã£o de duas etapas (2FA).
  - ExtraÃ§Ã£o de dados de perfil (Bio).
  - SaÃ­da de dados em formato JSON.
- **Coleta de NotÃ­cias**:
  - Scraping de manchetes do G1.
  - ExtraÃ§Ã£o de tÃ­tulo, link e resumo.
  - SaÃ­da de dados em formato JSON.

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3**
- **Selenium**: Para automaÃ§Ã£o de navegador.
- **python-dotenv**: Para gerenciamento de variÃ¡veis de ambiente.
- **webdriver-manager**: Para gerenciamento automÃ¡tico do ChromeDriver.

---

## ğŸš€ Como Executar

Siga os passos abaixo para configurar e rodar o projeto.

### 1. PrÃ©-requisitos

- Python 3.8 ou superior.
- Google Chrome instalado.

### 2. ConfiguraÃ§Ã£o do Ambiente

**Clone o repositÃ³rio:**

```bash
git clone https://github.com/alyssonrafael/Algoritimos_e_complexidade
cd web_scraping_com_selenium
```

**Crie e ative um ambiente virtual:**

```bash
# Criar o ambiente
python -m venv venv

# Ativar no Windows
.\venv\Scripts\activate

# Ativar no macOS/Linux
source venv/bin/activate
```

### 3. InstalaÃ§Ã£o das DependÃªncias

Instale todas as bibliotecas listadas no `requirements.txt` com um Ãºnico comando:

```bash
pip install -r requirements.txt
```

### 4. ConfiguraÃ§Ã£o das Credenciais

Crie um arquivo chamado `.env` ou renomeie o `.env.example` na raiz da pasta e adicione suas credenciais do Instagram:

```ini
INSTAGRAM_USER="seu_usuario_aqui"
INSTAGRAM_PASS="sua_senha_aqui"
```

### 5. ExecuÃ§Ã£o

Execute o orquestrador principal para iniciar o menu:

```bash
python main.py
```

Escolha a opÃ§Ã£o desejada no menu e siga as instruÃ§Ãµes no terminal.

---

## ğŸ“š MÃ³dulos

- **ğŸ¤– Bot do Instagram**: Focado em automaÃ§Ã£o de login e extraÃ§Ã£o de dados do Instagram.
  - [Clique aqui para a documentaÃ§Ã£o detalhada do bot.](./boot_login/README.md)
- **ğŸ“° Coletor de NotÃ­cias**: Focado em web scraping de portais de notÃ­cias.
  - [Clique aqui para a documentaÃ§Ã£o detalhada do coletor.](./noticias/README.md)

---

## ğŸ‘¨â€ğŸ’» Autor

Alysson Rafael

202212048944

ciencias da computaÃ§Ã£o

24/09/2025

link do funcionamento do programa [Clique aqui](https://youtu.be/-P5q24GUq4U)

---

## âš ï¸ ObservaÃ§Ãµes e Ã‰tica

- Este projeto foi desenvolvido exclusivamente para **fins educacionais** e como demonstraÃ§Ã£o de habilidades em automaÃ§Ã£o e web scraping.
- A automaÃ§Ã£o de plataformas e redes sociais pode violar os **Termos de ServiÃ§o** dos sites. Utilize este cÃ³digo por sua conta e risco.
- **NÃ£o utilize** web scraping ou automaÃ§Ã£o em sites que nÃ£o permitem a prÃ¡tica ou para coletar dados pessoais sensÃ­veis, respeitando a privacidade e a Lei Geral de ProteÃ§Ã£o de Dados (LGPD).
- Para testes de login, dÃª preferÃªncia ao uso de **contas de teste** ou sites de demonstraÃ§Ã£o criados para este fim.
